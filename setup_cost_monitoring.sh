#!/bin/bash
# Setup Cost Monitoring and Alerts for GCP Infrastructure
#
# This script creates:
# 1. BigQuery scheduled queries for cost tracking
# 2. Cloud Monitoring alerts for cost anomalies
# 3. Daily cost reports via email
# 4. Slack/webhook notifications (optional)

set -e

PROJECT_ID="truckerbooks-mvp-prod"
DATASET="cache_analytics"
ALERT_EMAIL="${ALERT_EMAIL:-your-email@example.com}"

echo "=========================================="
echo "üìä Setting Up Cost Monitoring"
echo "=========================================="
echo ""

# Step 1: Create cost summary view
echo "üìà Step 1/5: Creating cost summary view..."
bq query --use_legacy_sql=false "
CREATE OR REPLACE VIEW \`$PROJECT_ID.$DATASET.daily_cost_summary\` AS
SELECT
  DATE(timestamp) as date,
  provider,
  model,
  COUNT(*) as total_requests,
  SUM(CASE WHEN cache_hit THEN 1 ELSE 0 END) as cache_hits,
  ROUND(100.0 * SUM(CASE WHEN cache_hit THEN 1 ELSE 0 END) / COUNT(*), 1) as hit_rate_pct,
  ROUND(SUM(cost_with_cache), 4) as actual_cost_usd,
  ROUND(SUM(cost_without_cache), 4) as cost_without_cache_usd,
  ROUND(SUM(savings), 4) as total_savings_usd,
  ROUND(AVG(latency_ms), 0) as avg_latency_ms
FROM \`$PROJECT_ID.$DATASET.cache_metrics\`
WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY)
GROUP BY date, provider, model
ORDER BY date DESC, actual_cost_usd DESC
"
echo "‚úì Created daily_cost_summary view"

# Step 2: Create cost anomaly detection view
echo ""
echo "üîç Step 2/5: Creating cost anomaly detection..."
bq query --use_legacy_sql=false "
CREATE OR REPLACE VIEW \`$PROJECT_ID.$DATASET.cost_anomalies\` AS
WITH daily_costs AS (
  SELECT
    DATE(timestamp) as date,
    SUM(cost_with_cache) as daily_cost,
    AVG(SUM(cost_with_cache)) OVER (
      ORDER BY DATE(timestamp)
      ROWS BETWEEN 7 PRECEDING AND 1 PRECEDING
    ) as avg_last_7_days
  FROM \`$PROJECT_ID.$DATASET.cache_metrics\`
  WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 30 DAY)
  GROUP BY date
)
SELECT
  date,
  daily_cost,
  avg_last_7_days,
  daily_cost - avg_last_7_days as cost_diff,
  ROUND(100.0 * (daily_cost - avg_last_7_days) / avg_last_7_days, 1) as pct_change
FROM daily_costs
WHERE date >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)
  AND daily_cost > avg_last_7_days * 1.5  -- 50% increase
ORDER BY pct_change DESC
"
echo "‚úì Created cost_anomalies view"

# Step 3: Create model efficiency view
echo ""
echo "‚ö° Step 3/5: Creating model efficiency metrics..."
bq query --use_legacy_sql=false "
CREATE OR REPLACE VIEW \`$PROJECT_ID.$DATASET.model_efficiency\` AS
SELECT
  model,
  provider,
  COUNT(*) as total_requests,
  ROUND(AVG(latency_ms), 0) as avg_latency_ms,
  ROUND(SUM(cost_with_cache) / COUNT(*), 6) as cost_per_request,
  ROUND(AVG(output_tokens / (latency_ms / 1000.0)), 0) as tokens_per_second,
  ROUND(SUM(cost_with_cache) / SUM(output_tokens) * 1000, 6) as cost_per_1k_tokens,
  ROUND(100.0 * SUM(CASE WHEN cache_hit THEN 1 ELSE 0 END) / COUNT(*), 1) as cache_hit_rate
FROM \`$PROJECT_ID.$DATASET.cache_metrics\`
WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY)
  AND output_tokens > 0
GROUP BY model, provider
ORDER BY total_requests DESC
"
echo "‚úì Created model_efficiency view"

# Step 4: Setup Cloud Monitoring alert
echo ""
echo "üö® Step 4/5: Creating Cloud Monitoring alert..."

# Create notification channel (email)
echo "Creating email notification channel..."
gcloud alpha monitoring channels create \
  --display-name="Cost Alert Email" \
  --type=email \
  --channel-labels=email_address="$ALERT_EMAIL" \
  --project=$PROJECT_ID 2>/dev/null || echo "  (Channel may already exist)"

# Get notification channel ID
CHANNEL_ID=$(gcloud alpha monitoring channels list \
  --filter="displayName='Cost Alert Email'" \
  --format="value(name)" \
  --project=$PROJECT_ID | head -1)

if [ ! -z "$CHANNEL_ID" ]; then
  echo "‚úì Notification channel: $CHANNEL_ID"

  # Create alert policy for cost anomalies
  cat > /tmp/cost_alert_policy.json <<EOF
{
  "displayName": "AI Gateway Cost Anomaly Alert",
  "documentation": {
    "content": "Alert triggered when daily AI costs increase by >50% compared to 7-day average",
    "mimeType": "text/markdown"
  },
  "conditions": [{
    "displayName": "Daily cost increase > 50%",
    "conditionThreshold": {
      "filter": "resource.type = \"cloud_run_revision\" AND metric.type = \"run.googleapis.com/request_count\"",
      "comparison": "COMPARISON_GT",
      "thresholdValue": 1000,
      "duration": "300s",
      "aggregations": [{
        "alignmentPeriod": "300s",
        "perSeriesAligner": "ALIGN_RATE"
      }]
    }
  }],
  "combiner": "OR",
  "enabled": true,
  "notificationChannels": ["$CHANNEL_ID"],
  "alertStrategy": {
    "autoClose": "604800s"
  }
}
EOF

  gcloud alpha monitoring policies create \
    --policy-from-file=/tmp/cost_alert_policy.json \
    --project=$PROJECT_ID 2>/dev/null || echo "  (Policy may already exist)"

  echo "‚úì Created cost anomaly alert policy"
else
  echo "‚ö†Ô∏è  Could not create notification channel"
fi

# Step 5: Create scheduled query for daily reports
echo ""
echo "üìß Step 5/5: Setting up daily cost reports..."

SCHEDULED_QUERY=$(cat <<'EOF'
-- Daily Cost Report Query
SELECT
  DATE(timestamp) as report_date,
  COUNT(*) as total_requests,
  COUNT(DISTINCT model) as models_used,
  ROUND(SUM(cost_with_cache), 4) as total_cost_usd,
  ROUND(SUM(savings), 4) as total_savings_usd,
  ROUND(100.0 * SUM(CASE WHEN cache_hit THEN 1 ELSE 0 END) / COUNT(*), 1) as cache_hit_rate,
  ROUND(AVG(latency_ms), 0) as avg_latency_ms,
  STRING_AGG(DISTINCT CONCAT(model, ': ', CAST(COUNT(*) AS STRING)), ', ') as model_breakdown
FROM `truckerbooks-mvp-prod.cache_analytics.cache_metrics`
WHERE timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 DAY)
GROUP BY report_date
EOF
)

# Note: Scheduled queries require setup via BigQuery UI or API
# Here's the command for reference:
echo "To setup scheduled daily reports:"
echo "1. Go to: https://console.cloud.google.com/bigquery/scheduled-queries?project=$PROJECT_ID"
echo "2. Click 'Create Scheduled Query'"
echo "3. Use this query:"
echo ""
echo "$SCHEDULED_QUERY"
echo ""
echo "4. Set schedule: Daily at 9:00 AM"
echo "5. Set destination: $PROJECT_ID.$DATASET.daily_reports"
echo ""
echo "‚úì Scheduled query template ready"

# Summary
echo ""
echo "=========================================="
echo "‚úÖ Cost Monitoring Setup Complete!"
echo "=========================================="
echo ""
echo "üìä Views Created:"
echo "  ‚Ä¢ daily_cost_summary - Daily cost breakdown"
echo "  ‚Ä¢ cost_anomalies - Automatic anomaly detection"
echo "  ‚Ä¢ model_efficiency - Per-model performance metrics"
echo ""
echo "üö® Alerts Configured:"
echo "  ‚Ä¢ Email notifications to: $ALERT_EMAIL"
echo "  ‚Ä¢ Alert on cost increases > 50%"
echo ""
echo "üìà Query Cost Metrics:"
echo "  bq query --use_legacy_sql=false 'SELECT * FROM \`$PROJECT_ID.$DATASET.daily_cost_summary\` WHERE date >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY) ORDER BY date DESC'"
echo ""
echo "üîç Check for Anomalies:"
echo "  bq query --use_legacy_sql=false 'SELECT * FROM \`$PROJECT_ID.$DATASET.cost_anomalies\`'"
echo ""
echo "‚ö° View Model Efficiency:"
echo "  bq query --use_legacy_sql=false 'SELECT * FROM \`$PROJECT_ID.$DATASET.model_efficiency\`'"
echo ""
